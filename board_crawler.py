"""
ê²Œì‹œíŒ í¬ë¡¤ëŸ¬ ëª¨ë“ˆ
- í™ˆí˜ì´ì§€ ê²Œì‹œíŒì—ì„œ ì œëª©ê³¼ ë‚´ìš© ì¶”ì¶œ
- ìì—°ì–´ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
"""
import re
import time
import logging
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException

from config import LOG_FILE, LOG_FORMAT
from models import save_board_mapping, init_database

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# ê²Œì‹œíŒ ì¹´í…Œê³ ë¦¬ë³„ URL ë° question ë²ˆí˜¸ ë§¤í•‘
BOARD_CONFIG = {
    "í‘œì‹œê¸°ì¤€": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=EJ2GKW3",
        "questions": [
            "question_161", "question_217", "question_101", "question_103",
            "question_222", "question_105", "question_100", "question_104",
            "question_219", "question_221", "question_218", "question_220",
            "question_212", "question_213", "question_216", "question_214",
            "question_167"
        ]
    },
    "ì”ë¥˜ë†ì•½_í•­ìƒë¬¼ì§ˆ": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=MKJ9PKO0",
        "questions": [
            "question_82", "question_83", "question_85", "question_84",
            "question_87", "question_88", "question_89", "question_90",
            "question_91", "question_93", "question_154", "question_166"
        ]
    },
    "ë°©ì‚¬ëŠ¥": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=HY5KJJJI",
        "questions": [
            "question_37", "question_38", "question_39", "question_42",
            "question_43", "question_44", "question_46", "question_47"
        ]
    },
    "ì˜ì–‘ì„±ë¶„": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=JEKb3KXA",
        "questions": [
            "question_207", "question_78", "question_148", "question_193",
            "question_192", "question_80", "question_79", "question_173",
            "question_172", "question_174", "question_170", "question_182",
            "question_171", "question_175", "question_176", "question_177",
            "question_178", "question_180", "question_181", "question_245",
            "question_179", "question_183", "question_169", "question_81",
            "question_164"
        ]
    },
    "ì†Œë¹„ê¸°í•œ": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=PXXBybSV",
        "questions": [
            "question_94", "question_97", "question_95", "question_98",
            "question_99"
        ]
    },
    "ì•Œë ˆë¥´ê¸°": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=G7K3Y2F9",
        "questions": [
            "question_26", "question_27", "question_156", "question_28",
            "question_29", "question_31", "question_151", "question_251",
            "question_153", "question_32", "question_152", "question_35",
            "question_157", "question_231", "question_250", "question_33",
            "question_34", "question_160", "question_30"
        ]
    },
    "ì´ë¬¼": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=H5R6T8B3",
        "questions": [
            "question_122", "question_159", "question_136", "question_139",
            "question_134", "question_187", "question_135", "question_138",
            "question_140"
        ]
    },
    "ë¹„ê±´_í• ë„_ë™ë¬¼DNA": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=D4P8L2M7",
        "questions": [
            "question_184", "question_124", "question_185", "question_126",
            "question_125", "question_186", "question_127", "question_128",
            "question_130", "question_188"
        ]
    },
    "ì¶•ì‚°": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=XN0Cd4r7",
        "questions": [
            "question_66", "question_202", "question_209", "question_203",
            "question_204", "question_72", "question_69", "question_205",
            "question_71", "question_163", "question_206", "question_73",
            "question_74", "question_76", "question_240", "question_243",
            "question_246"
        ]
    },
    "ì‹í’ˆ": {
        "base_url": "https://www.biofl.co.kr/sub.jsp?code=7r9P7y94",
        "questions": [
            "question_48", "question_199", "question_208", "question_64",
            "question_63", "question_198", "question_162", "question_60",
            "question_53", "question_201", "question_62", "question_56",
            "question_57", "question_51", "question_50", "question_65",
            "question_236", "question_239", "question_241"
        ]
    }
}


class BoardCrawler:
    """ê²Œì‹œíŒ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤"""

    def __init__(self):
        self._driver = None

    def _get_driver(self):
        """Selenium WebDriver ìƒì„±"""
        if self._driver is None:
            try:
                options = Options()
                options.add_argument("--headless=new")
                options.add_argument("--no-sandbox")
                options.add_argument("--disable-dev-shm-usage")
                options.add_argument("--disable-gpu")
                options.add_argument("--window-size=1920,1080")
                self._driver = webdriver.Chrome(options=options)
                logger.info("WebDriver ìƒì„± ì™„ë£Œ")
            except Exception as e:
                logger.error(f"WebDriver ìƒì„± ì‹¤íŒ¨: {e}")
                raise
        return self._driver

    def close(self):
        """WebDriver ì¢…ë£Œ"""
        if self._driver:
            self._driver.quit()
            self._driver = None
            logger.info("WebDriver ì¢…ë£Œ")

    def crawl_board_content(self, category: str, base_url: str, question_id: str) -> dict:
        """
        íŠ¹ì • ê²Œì‹œíŒ íŒì—…ì—ì„œ ì œëª©ê³¼ ë‚´ìš© ì¶”ì¶œ
        - answerPopOpen ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ íŒì—… ë‚´ìš© ë¡œë“œ
        - answerWrapì—ì„œ ì‹¤ì œ Q&A ë‚´ìš© ì¶”ì¶œ

        Args:
            category: ì¹´í…Œê³ ë¦¬ëª…
            base_url: ê¸°ë³¸ URL
            question_id: question_XXX í˜•ì‹ì˜ ID

        Returns:
            {"title": ì œëª©, "content": ë‚´ìš©} ë˜ëŠ” None
        """
        driver = self._get_driver()

        try:
            # 1. ê¸°ë³¸ í˜ì´ì§€ ë¡œë“œ
            driver.get(base_url)
            time.sleep(1.5)

            # 2. í•´ë‹¹ questionì˜ íŒì—… ë§í¬ ì°¾ê¸° ë° í´ë¦­
            popup_link_selector = f'a[data-needpopup-show="#{question_id}"]'
            try:
                popup_link = driver.find_element(By.CSS_SELECTOR, popup_link_selector)

                # ë§í¬ í…ìŠ¤íŠ¸ê°€ ì§ˆë¬¸ ì œëª©
                link_text = popup_link.text.strip()

                # í´ë¦­í•˜ì—¬ íŒì—… ì—´ê¸°
                driver.execute_script("arguments[0].click();", popup_link)
                time.sleep(1)  # íŒì—… ë¡œë”© ëŒ€ê¸°

            except NoSuchElementException:
                logger.warning(f"âš ï¸ {category}/{question_id}: íŒì—… ë§í¬ ì—†ìŒ")
                return None

            # 3. íŒì—… ë‚´ìš© ì¶”ì¶œ
            title = link_text  # ë§í¬ í…ìŠ¤íŠ¸ê°€ ì œëª©
            content = None

            # answerWrap ë‚´ìš© ì¶”ì¶œ ì‹œë„
            content_selectors = [
                f"#{question_id} .answerWrap",
                f"#{question_id} .answerLayer",
                f"#{question_id}"
            ]

            for selector in content_selectors:
                try:
                    elem = driver.find_element(By.CSS_SELECTOR, selector)
                    if elem and elem.text.strip():
                        content = elem.text.strip()
                        break
                except NoSuchElementException:
                    continue

            # 4. íŒì—… ë‹«ê¸° (ë‹¤ìŒ í¬ë¡¤ë§ì„ ìœ„í•´)
            try:
                close_btn = driver.find_element(By.CSS_SELECTOR, f"#{question_id} .close, #{question_id} .btn-close, .needpopup-close")
                driver.execute_script("arguments[0].click();", close_btn)
            except NoSuchElementException:
                # ESC í‚¤ë¡œ ë‹«ê¸° ì‹œë„
                from selenium.webdriver.common.keys import Keys
                driver.find_element(By.TAG_NAME, "body").send_keys(Keys.ESCAPE)
            time.sleep(0.3)

            if title or content:
                logger.info(f"âœ… {category}/{question_id}: {title[:30] if title else 'N/A'}...")
                return {"title": title, "content": content}
            else:
                logger.warning(f"âš ï¸ {category}/{question_id}: ë‚´ìš© ì¶”ì¶œ ì‹¤íŒ¨")
                return None

        except TimeoutException:
            logger.error(f"âŒ {category}/{question_id}: íƒ€ì„ì•„ì›ƒ")
            return None
        except Exception as e:
            logger.error(f"âŒ {category}/{question_id}: {e}")
            return None

    def crawl_category(self, category: str) -> int:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ëª¨ë“  ê²Œì‹œíŒ í¬ë¡¤ë§

        Args:
            category: ì¹´í…Œê³ ë¦¬ëª…

        Returns:
            ì„±ê³µí•œ í•­ëª© ìˆ˜
        """
        if category not in BOARD_CONFIG:
            logger.error(f"ì•Œ ìˆ˜ ì—†ëŠ” ì¹´í…Œê³ ë¦¬: {category}")
            return 0

        config = BOARD_CONFIG[category]
        base_url = config["base_url"]
        questions = config["questions"]

        success_count = 0
        for question_id in questions:
            result = self.crawl_board_content(category, base_url, question_id)

            if result:
                save_board_mapping(
                    question_id=question_id,
                    category=category,
                    base_url=base_url,
                    title=result.get("title"),
                    content=result.get("content")
                )
                success_count += 1

            time.sleep(0.5)  # ì„œë²„ ë¶€í•˜ ë°©ì§€

        logger.info(f"ğŸ“Š {category}: {success_count}/{len(questions)} ì™„ë£Œ")
        return success_count

    def crawl_all(self) -> dict:
        """ëª¨ë“  ì¹´í…Œê³ ë¦¬ í¬ë¡¤ë§"""
        logger.info("=" * 50)
        logger.info("ì „ì²´ ê²Œì‹œíŒ í¬ë¡¤ë§ ì‹œì‘")
        logger.info("=" * 50)

        results = {}
        total_success = 0
        total_count = 0

        for category in BOARD_CONFIG:
            count = self.crawl_category(category)
            results[category] = count
            total_success += count
            total_count += len(BOARD_CONFIG[category]["questions"])

        logger.info("=" * 50)
        logger.info(f"ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {total_success}/{total_count}")
        logger.info("=" * 50)

        return results


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # DB ì´ˆê¸°í™”
    init_database()

    crawler = BoardCrawler()
    try:
        results = crawler.crawl_all()

        print("\nğŸ“Š í¬ë¡¤ë§ ê²°ê³¼:")
        print("-" * 40)
        for category, count in results.items():
            total = len(BOARD_CONFIG[category]["questions"])
            print(f"  {category}: {count}/{total}")
        print("-" * 40)

    finally:
        crawler.close()


if __name__ == "__main__":
    main()
